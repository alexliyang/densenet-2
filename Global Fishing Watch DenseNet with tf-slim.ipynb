{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WIP: Prep to implement DenseNet for GFW vessel classification\n",
    "##### Implementation in Slim for GFW\n",
    "##### ....need to get MNIST working first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bn_relu_conv(net, n_channels, drop, is_training=True, scope=\"bn_relu_conv\"):\n",
    "    with tf.variable_scope(scope, 'bn_relu_conv', [net]):\n",
    "         with slim.arg_scope([slim.conv2d], padding = 'SAME',\n",
    "                            activation_fn=tf.nn.relu):\n",
    "            net = tf.contrib.layers.batch_norm(net)\n",
    "            net = slim.conv2d(net, n_channels, [3, 3])\n",
    "            net = slim.dropout(net, drop, is_training=is_training)\n",
    "            return net\n",
    "\n",
    "def add_layer(net, n_channels, drop, is_training = True):\n",
    "    net = bn_relu_conv(net, n_channels, drop, is_training)\n",
    "    return net\n",
    "\n",
    "def transition(net, n_channels, drop):\n",
    "    net = bn_relu_conv(net, n_channels, drop)\n",
    "    net = slim.max_pool2d(net, [2, 2], stride=[2, 2], padding='SAME')\n",
    "    return net\n",
    "\n",
    "def bn_relu_conv_model(input, n_channels, growth_rate, n_classes, levels, drop, is_training):\n",
    "        \n",
    "    with slim.arg_scope([slim.conv2d], padding = 'SAME', activation_fn=tf.nn.relu):\n",
    "        with slim.arg_scope([slim.fully_connected], activation_fn=tf.nn.relu):\n",
    "            net = slim.conv2d(input, n_channels, [3, 3])\n",
    "\n",
    "            for i in range(levels):\n",
    "                add_layer(net, n_channels, drop, is_training)\n",
    "                n_channels += growth_rate\n",
    "            transition(net, n_channels, drop)\n",
    "\n",
    "            net = tf.contrib.layers.batch_norm(net)\n",
    "            net = slim.conv2d(net, n_channels, [3, 3])\n",
    "            net = slim.flatten(net)\n",
    "            net = slim.fully_connected(net, n_classes)\n",
    "            return net\n",
    "\n",
    "class Model(ModelBase):\n",
    "    \n",
    "    feature_depth = 20\n",
    "    start_channels = 16\n",
    "    n_classes = 10\n",
    "    drop = 0.2\n",
    "    growth_rate = 12\n",
    "    levels = 10\n",
    "    \n",
    "    def zero_pad_features(self, features):\n",
    "        \"\"\" Zero-pad features in the depth dimension to match requested feature depth. \"\"\"\n",
    "\n",
    "        feature_pad_size = self.feature_depth - self.num_feature_dimensions\n",
    "        assert (feature_pad_size >= 0)\n",
    "        zero_padding = tf.zeros([self.batch_size, 1, self.window_max_points,\n",
    "                                 feature_pad_size])\n",
    "        padded = tf.concat(3, [features, zero_padding])\n",
    "\n",
    "        return padded\n",
    "    \n",
    "    def build_training_net(self, features, labels):\n",
    "        n_channels = self.start_channels\n",
    "\n",
    "        features = self.zero_pad_features(features)\n",
    "        one_hot_labels = slim.one_hot_encoding(labels, self.n_classes)\n",
    "\n",
    "        logits = bn_relu_conv_model(features, n_channels, self.growth_rate, \n",
    "                                    self.n_classes, self.levels, self.drop, True)\n",
    "\n",
    "        loss = slim.losses.softmax_cross_entropy(logits, one_hot_labels)\n",
    "\n",
    "        optimizer = tf.train.AdadeltaOptimizer(2e-5)\n",
    "\n",
    "        return TrainNetInfo(loss, optimizer, logits)\n",
    "\n",
    "\n",
    "    def build_inference_net(self, features):\n",
    "        n_channels = self.start_channels\n",
    "\n",
    "        features = self.zero_pad_features(features)\n",
    "\n",
    "        logits = bn_relu_conv_model(features, n_channels, self.growth_rate, \n",
    "                                    self.n_classes, self.levels, self.drop, False)\n",
    "\n",
    "        return logits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
